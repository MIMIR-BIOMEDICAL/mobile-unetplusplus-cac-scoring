{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7e104-f67e-4fbe-ad54-7a4eb0d5e210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom as pdc\n",
    "import sklearn.metrics as skm\n",
    "import tensorflow as tf\n",
    "from keras.utils.layer_utils import count_params\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(pathlib.Path.cwd().parent.as_posix())\n",
    "\n",
    "from src.data.preprocess.lib.utils import get_patient_split\n",
    "from src.models.lib.builder import build_unet_pp\n",
    "from src.models.lib.config import UNetPPConfig\n",
    "from src.models.lib.data_loader import create_dataset, preprocess_img\n",
    "from src.models.lib.loss import (\n",
    "    dice_coef,\n",
    "    dice_coef_nosq,\n",
    "    log_cosh_dice_loss,\n",
    "    log_cosh_dice_loss_nosq,\n",
    ")\n",
    "from src.models.lib.utils import loss_dict_gen\n",
    "from src.system.pipeline.output import auto_cac, ground_truth_auto_cac\n",
    "\n",
    "project_root_path = pathlib.Path.cwd().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086daf94-be66-487e-8416-52db4cde869e",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6bb6af-8d14-48f9-888a-253d5293ed56",
   "metadata": {},
   "source": [
    "### Main Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2836919-23a2-48a0-aac3-cb27e6410b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model\n",
    "model_root_path = project_root_path / \"models\" / \"path\"  # Change this\n",
    "model_paths = list((model_root_path).rglob(\"*model*\"))\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bc23b-6aac-47f2-a4b7-249f5e904ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main model\n",
    "selected_model_path = model_paths[0].as_posix()\n",
    "loss_func = log_cosh_dice_loss\n",
    "\n",
    "main_model = tf.keras.models.load_model(\n",
    "    selected_model_path,\n",
    "    custom_objects={\n",
    "        \"log_cosh_dice_loss\": loss_func,\n",
    "        \"dice_coef_nosq\": dice_coef_nosq,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062489f-35e1-4080-8af4-5b1cb818ea8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pruned Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869cb68-8b48-4888-b2d5-f3cd320d3ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_depth = 5\n",
    "filter_list = [16, 32, 64, 128, 256]\n",
    "\n",
    "\n",
    "pruned_model = {}\n",
    "\n",
    "\n",
    "for depth in range(1, model_depth):\n",
    "    pruned_model[f\"d{depth}\"] = {}\n",
    "\n",
    "    model_config = UNetPPConfig(\n",
    "        model_name=f\"model_d{depth}\",\n",
    "        upsample_mode=\"transpose\",\n",
    "        depth=depth + 1,\n",
    "        input_dim=[512, 512, 1],\n",
    "        batch_norm=True,\n",
    "        deep_supervision=False,\n",
    "        model_mode=\"basic\",\n",
    "        n_class={\"bin\": 1},\n",
    "        filter_list=filter_list[: depth + 1],\n",
    "    )\n",
    "\n",
    "    model, output_layer_name = build_unet_pp(model_config, custom=True)\n",
    "\n",
    "    print(f\"-- Creating pruned model d{depth}\")\n",
    "    for layer in tqdm(model.layers):\n",
    "        pruned_layer_name = layer.name\n",
    "\n",
    "        main_model_layer = main_model.get_layer(pruned_layer_name)\n",
    "\n",
    "        main_model_weight = main_model_layer.get_weights()\n",
    "\n",
    "        layer.set_weights(main_model_weight)\n",
    "\n",
    "    pruned_model[f\"d{depth}\"][\"model\"] = model\n",
    "\n",
    "    loss_dict = loss_dict_gen(model_config, output_layer_name, [loss_func])\n",
    "\n",
    "    pruned_model[f\"d{depth}\"][\"dataset\"] = create_dataset(\n",
    "        project_root_path, model_config, 2, 1\n",
    "    )\n",
    "\n",
    "    pruned_model[f\"d{depth}\"][\"config\"] = model_config\n",
    "    pruned_model[f\"d{depth}\"][\"loss_dict\"] = loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc1766-0d8a-4fb5-b378-0d0a3f3e63b6",
   "metadata": {},
   "source": [
    "### Pruned Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f1b21-bd9b-4be0-b261-5e5f924023a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1, model_depth):\n",
    "    print(depth)\n",
    "\n",
    "    pruned_model[f\"d{depth}\"][\"trainable_weights\"] = count_params(\n",
    "        pruned_model[f\"d{depth}\"][\"model\"].trainable_weights\n",
    "    )\n",
    "    pruned_model[f\"d{depth}\"][\"non_trainable_weights\"] = count_params(\n",
    "        pruned_model[f\"d{depth}\"][\"model\"].non_trainable_weights\n",
    "    )\n",
    "    pruned_model[f\"d{depth}\"][\"weights\"] = count_params(\n",
    "        pruned_model[f\"d{depth}\"][\"model\"].weights\n",
    "    )\n",
    "\n",
    "    metrics = [\n",
    "        dice_coef,\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "    ]\n",
    "\n",
    "    pruned_model[f\"d{depth}\"][\"model\"].compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=pruned_model[f\"d{depth}\"][\"loss_dict\"],\n",
    "        metrics=metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585e21a-1b85-4aa0-b8e1-eb6cf7cef32c",
   "metadata": {},
   "source": [
    "### Evaluate Model (Quantitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a86592-1dd3-4d08-924d-11bf3e96a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1, model_depth):\n",
    "    print(f\"Evaluate model d{depth} on test dataset\")\n",
    "    pruned_model[f\"d{depth}\"][\"model\"].evaluate(\n",
    "        pruned_model[f\"d{depth}\"][\"dataset\"][\"test\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05c566-b6c0-46d2-b55a-87f1139c1a7b",
   "metadata": {},
   "source": [
    "### Evaluate Model (Qualitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf8af4-83cd-4cfe-b060-0093fcb3a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Segment\n",
    "patient_idx = 0\n",
    "patient_img_idx = 0\n",
    "bin_json_path = list(project_root_path.rglob(\"bin*.json\"))[0]\n",
    "\n",
    "with bin_json_path.open(mode=\"r\") as json_file:\n",
    "    bin_dict_output = json.load(json_file)\n",
    "\n",
    "patient_info = bin_dict_output[str(patient_idx).zfill(3)]\n",
    "patient_img_info = patient_info[patient_img_idx]\n",
    "\n",
    "\n",
    "# Create lesion mask\n",
    "patient_img_lesion = np.zeros((512, 512))\n",
    "patient_img_lesion[tuple(zip(*patient_img_info[\"pos\"]))] = 1\n",
    "\n",
    "# Get patient img\n",
    "patient_img_num = patient_img_info[\"idx\"]\n",
    "\n",
    "print(\n",
    "    f\"Patient {patient_idx} Image {patient_img_idx+1}/{len(patient_info)} ({patient_img_num})\"\n",
    ")\n",
    "\n",
    "patient_root_path = next(project_root_path.rglob(f\"patient/{patient_idx}\"))\n",
    "patient_dcm_path = next(\n",
    "    patient_root_path.rglob(f\"*00{str(patient_img_num).lstrip('0').zfill(2)}.dcm\")\n",
    ")\n",
    "print(patient_dcm_path)\n",
    "patient_dcm = pdc.dcmread(patient_dcm_path)\n",
    "patient_img_arr = patient_dcm.pixel_array\n",
    "patient_img_hu = pdc.pixel_data_handlers.util.apply_modality_lut(\n",
    "    patient_img_arr, patient_dcm\n",
    ")\n",
    "patient_img_hu_pre = preprocess_img(patient_img_hu)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 60))\n",
    "\n",
    "ax[0].set_title(\"Image\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].imshow(patient_img_hu, cmap=\"gray\", interpolation=\"none\")\n",
    "\n",
    "ax[1].set_title(\"Binary Segment\")\n",
    "ax[1].imshow(np.ones([512, 512]), cmap=\"gray\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].imshow(patient_img_lesion, cmap=\"gray\")\n",
    "\n",
    "ax[2].set_title(\"ROI Overlay\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[2].imshow(patient_img_hu_pre, cmap=\"gray\", interpolation=\"none\")\n",
    "ax[2].imshow(patient_img_lesion, cmap=\"gray\", alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b67226-7f81-470e-b8c1-7981788b54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Non Segment\n",
    "patient_idx = 0\n",
    "patient_img_idx = 0\n",
    "\n",
    "\n",
    "patient_root_path = next(project_root_path.rglob(f\"patient/{patient_idx}\"))\n",
    "patient_dcm_path = next(\n",
    "    patient_root_path.rglob(f\"*00{str(patient_img_idx).lstrip('0').zfill(2)}.dcm\")\n",
    ")\n",
    "print(patient_dcm_path)\n",
    "patient_dcm = pdc.dcmread(patient_dcm_path)\n",
    "patient_img_arr = patient_dcm.pixel_array\n",
    "patient_img_hu = pdc.pixel_data_handlers.util.apply_modality_lut(\n",
    "    patient_img_arr, patient_dcm\n",
    ")\n",
    "patient_img_hu_pre = preprocess_img(patient_img_hu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde83643-9819-4068-a568-233452b66569",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model_input = np.expand_dims(np.expand_dims(patient_img_hu_pre, axis=0), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa68b2e-a2bf-4361-82a5-d2aee25b9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Output\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 8), constrained_layout=True)\n",
    "ax_map = {4: ax[0][1], 3: ax[0][2], 2: ax[1][1], 1: ax[1][2], 0: ax[0][0]}\n",
    "ax_map[0].set_title(\"Ground Truth\")\n",
    "ax_map[0].axis(\"off\")\n",
    "ax_map[0].imshow(patient_img_hu, cmap=\"gray\", interpolation=\"none\")\n",
    "ax_map[0].imshow(patient_img_lesion, cmap=\"gray\", alpha=0.5)\n",
    "ax[1][0].axis(\"off\")\n",
    "\n",
    "for depth in range(1, model_depth):\n",
    "    model_out = pruned_model[f\"d{depth}\"][\"model\"].predict(img_model_input)\n",
    "    model_bin_seg = (np.squeeze(model_out) > 0.5) * 1\n",
    "    print(np.max(model_bin_seg))\n",
    "\n",
    "    ax_map[depth].set_title(f\"Depth {depth} Prediction\")\n",
    "    ax_map[depth].axis(\"off\")\n",
    "    ax_map[depth].imshow(patient_img_hu, cmap=\"gray\", interpolation=\"none\")\n",
    "    ax_map[depth].imshow(model_bin_seg, cmap=\"gray\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025487c2-ed39-4f7a-a37e-850e1c6d0013",
   "metadata": {},
   "source": [
    "## System Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518da580-8551-4ec7-8310-74d20be0f159",
   "metadata": {},
   "source": [
    "### Prepare Ground Truth System Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75176522-3af7-4d10-b571-c6642548c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_json_path = list(project_root_path.rglob(\"bin*.json\"))[0]\n",
    "\n",
    "with bin_json_path.open(mode=\"r\") as json_file:\n",
    "    bin_dict_output = json.load(json_file)\n",
    "\n",
    "patient_test_data = set(get_patient_split([0.7, 0.2, 0.1])[\"test\"])\n",
    "patient_with_segment = set(bin_dict_output.keys())\n",
    "\n",
    "# Split patient with segmentation and no segmentation\n",
    "patient_test_with_segment = patient_with_segment.intersection(patient_test_data)\n",
    "patient_test_no_segment = patient_test_data.difference(patient_with_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c6f26-3b4d-456a-bed5-976896600217",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_test_data_dict = {}\n",
    "\n",
    "# Add ground truth data for patient without segmentation\n",
    "for idx_no_seg in patient_test_no_segment:\n",
    "    ground_test_data_dict[idx_no_seg] = {}\n",
    "    ground_test_data_dict[idx_no_seg][\"total_agatston\"] = 0\n",
    "    ground_test_data_dict[idx_no_seg][\"class\"] = \"Absent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8edea9-f2aa-4b78-b23e-0fe873f01adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_seg in tqdm(patient_test_with_segment):\n",
    "    patient_root_path = next(project_root_path.rglob(f\"patient/{idx_seg.lstrip('0')}\"))\n",
    "\n",
    "    img_path = [\n",
    "        next(\n",
    "            patient_root_path.rglob(\n",
    "                f\"*00{str(int(x['idx'].lstrip('0'))+0).zfill(2)}.dcm\"\n",
    "            )\n",
    "        )\n",
    "        for x in bin_dict_output[idx_seg]\n",
    "    ]\n",
    "    loc_list = [x[\"pos\"] for x in bin_dict_output[idx_seg]]\n",
    "\n",
    "    ground_test_data_dict[idx_seg] = ground_truth_auto_cac(\n",
    "        img_path, loc_list, mem_opt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50291098-4665-4db0-8a3d-8bd5a55d080d",
   "metadata": {},
   "source": [
    "### Get Output from Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d2f24-0a21-4119-8116-2af247161250",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_data_dict = {}\n",
    "\n",
    "for idx_seg in tqdm(patient_test_data):\n",
    "    patient_root_path = next(project_root_path.rglob(f\"patient/{idx_seg.lstrip('0')}\"))\n",
    "    img_path = list(patient_root_path.rglob(f\"*.dcm\"))\n",
    "    for depth in range(1, model_depth):\n",
    "        model_test_data_dict[f\"d{depth}\"] = model_test_data_dict.get(f\"d{depth}\", {})\n",
    "        model_test_data_dict[f\"d{depth}\"][idx_seg] = auto_cac(\n",
    "            img_path, pruned_model[f\"d{depth}\"][\"model\"], mem_opt=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99dc77-0807-4a90-8184-c388834eeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1, model_depth):\n",
    "    model_test_data_dict[f\"d{depth}\"] = dict(\n",
    "        sorted(model_test_data_dict[f\"d{depth}\"].items())\n",
    "    )\n",
    "ground_test_data_dict = dict(sorted(ground_test_data_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05bdff-0a16-4ecf-b9c4-97dc2f859633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_test_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be8ea9-bb00-4105-a948-84f8b3213c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_data_dict[f\"d4\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5cc7a-f53a-4ada-b4c3-1996896e419e",
   "metadata": {},
   "source": [
    "### Evaluate Agatston Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e102c-1f28-4f2d-bb3c-5c22f9658df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all agatston score for ground truth and model\n",
    "agatston_eval = {}\n",
    "\n",
    "\n",
    "def get_total_agatston(x):\n",
    "    return x[\"total_agatston\"]\n",
    "\n",
    "\n",
    "agatston_eval[\"ground_truth\"] = np.array(\n",
    "    list(map(get_total_agatston, list(ground_test_data_dict.values())))\n",
    ")\n",
    "\n",
    "for depth in range(1, model_depth):\n",
    "    agatston_eval[f\"d{depth}\"] = np.array(\n",
    "        list(map(get_total_agatston, list(model_test_data_dict[f\"d{depth}\"].values())))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0ecf4-32ab-4156-a4a5-b7c23aa7377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate\n",
    "def mae(a, b):\n",
    "    n = len(a)\n",
    "    err = a - b\n",
    "    return np.sum(np.absolute(err)) / n, np.std(err)\n",
    "\n",
    "\n",
    "for depth in range(1, model_depth):\n",
    "    print(\n",
    "        f\"MAE for model depth {depth} is {mae(agatston_eval['ground_truth'],agatston_eval[f'd{depth}'])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6bf65-467f-4e28-ad35-e5777f7b09bd",
   "metadata": {},
   "source": [
    "### Evaluate System Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98c3b6-4dae-48c2-b716-2665403ae5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(x):\n",
    "    return x[\"class\"]\n",
    "\n",
    "\n",
    "classification_eval = {}\n",
    "\n",
    "\n",
    "classification_eval[\"ground_truth\"] = list(\n",
    "    map(get_class, list(ground_test_data_dict.values()))\n",
    ")\n",
    "\n",
    "for depth in range(1, model_depth):\n",
    "    classification_eval[f\"d{depth}\"] = np.array(\n",
    "        list(map(get_class, list(model_test_data_dict[f\"d{depth}\"].values())))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74a5cf-e44e-4497-b95e-f3c066801817",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1, model_depth):\n",
    "    print(f\"Model {depth}\")\n",
    "    print(\n",
    "        skm.classification_report(\n",
    "            classification_eval[\"ground_truth\"], classification_eval[f\"d{depth}\"]\n",
    "        )\n",
    "    )\n",
    "    skm.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true=classification_eval[\"ground_truth\"],\n",
    "        y_pred=classification_eval[f\"d{depth}\"],\n",
    "        labels=[\"Absent\", \"Discrete\", \"Moderate\", \"Accentuated\"],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
